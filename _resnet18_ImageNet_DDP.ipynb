{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7RlbkDdJR_Qg"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIyxRbkJs-qi"},"outputs":[],"source":["# %cd \"/content/drive/MyDrive/data\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9eGg6YoyrFl"},"outputs":[],"source":["# !wget https://www.image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar #-p /content/drive/MyDrive/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXvs9A0ryCS1"},"outputs":[],"source":["# !wget https://www.image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar #-p /content/drive/MyDrive/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1oKSIRqveFE"},"outputs":[],"source":["# %ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_vJ8ZLA60hJ"},"outputs":[],"source":["# %cd \"/content/drive/MyDrive/data\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQS3c7XhxI0W"},"outputs":[],"source":["# # !chmod +x extract_ILSVR.sh\n","\n","# !sh /content/drive/MyDrive/data/extract_ILSVRC.sh"]},{"cell_type":"markdown","metadata":{"id":"EbW5IvNkBCkx"},"source":["## ImageNet setting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4747,"status":"ok","timestamp":1724254017976,"user":{"displayName":"김지윤","userId":"17984705331868413657"},"user_tz":-540},"id":"bT23tJST7QqG","outputId":"f9abc398-5f13-4c8f-af73-849bb3d0b068"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["import random\n","\n","import torchvision\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision import datasets\n","from torch.utils.data import DataLoader, Subset\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Function\n","from torch.cuda.amp import autocast, GradScaler\n","\n","from torch.nn.modules.batchnorm import BatchNorm2d\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import math\n","import copy\n","import time\n","import os\n","import json\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd \"/content/drive/MyDrive/Colab Notebooks\""]},{"cell_type":"markdown","metadata":{"id":"3ZT-wUahMsx2"},"source":["checkpoint vs. from scratch 확인"]},{"cell_type":"code","source":["def set_random_seeds(random_seed=0):\n","\n","  torch.manual_seed(random_seed)\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False\n","  np.random.seed(random_seed)\n","  random.seed(random_seed)\n","\n","set_random_seeds(10)"],"metadata":{"id":"pO4XNUU77tBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-oxSEjavddkT"},"outputs":[],"source":["# # !python -m torch.distributed.launch --nproc_per_node 1 ImageNet/DDP.py\n","# !torchrun --nnodes 1 --nproc_per_node 2 DDP.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BE1ZT-1TfRaC","outputId":"666a8fc3-963a-4687-c7fe-c2341202a455"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n","FINETUNE [ ResNet18_WCPC_1000 ]\n","BEST EVAL LOADED: 42.899999022483826 %\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n","DATALOADER...\n","----------------------------------------\n","                Training                \n","----------------------------------------\n","\t# corrects: 2 1 2 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 2 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 2 0 0 0 0 1 0 3 0 0 0 2 0 0 2 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 \n","Epoch: 000 Eval Loss: 16.8656 Eval Acc: 0.0008\n","\t# corrects: 2 1 0 0 0 2 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 2 1 0 0 0 0 0 1 3 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 6 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 2 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 2 1 1 2 0 0 3 0 1 0 0 0 0 1 0 0 0 1 2 0 0 0 0 0 0 0 2 0 2 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 3 1 0 1 0 1 0 0 1 0 0 2 0 0 1 1 1 1 0 0 1 0 3 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 2 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 2 0 0 1 0 2 0 0 0 1 0 1 2 3 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 2 0 0 0 0 0 1 1 0 0 0 0 2 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 2 0 0 1 1 0 1 1 0 2 2 2 0 0 0 2 1 1 3 0 0 0 0 0 0 1 1 0 0 1 2 2 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 2 0 2 2 1 0 2 1 0 0 1 0 0 0 0 0 0 0 1 2 0 1 0 2 2 2 1 1 1 3 1 0 1 0 1 1 0 2 1 0 0 2 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 3 1 0 0 1 3 2 1 0 0 1 1 0 0 0 0 0 1 2 0 0 0 0 0 1 0 0 0 0 1 1 2 0 0 0 0 1 0 1 0 1 2 0 4 1 0 0 0 1 0 1 0 2 0 0 1 0 1 2 1 0 0 1 0 0 1 0 1 0 2 2 1 0 3 0 0 0 0 0 1 0 1 1 1 2 1 0 2 1 1 0 2 1 0 1 0 1 1 0 1 0 1 0 0 0 2 1 1 0 0 0 0 0 0 0 1 1 2 0 1 1 0 0 0 2 0 1 1 1 0 1 0 1 2 1 3 1 2 1 0 0 0 1 2 0 0 1 0 0 2 0 1 0 0 0 0 0 0 3 2 0 0 1 0 0 2 0 0 0 0 0 0 1 2 0 0 2 1 0 0 0 0 0 1 1 0 0 1 3 1 1 1 0 2 1 2 0 0 0 0 1 1 4 1 0 0 0 1 0 0 0 0 0 1 0 1 2 0 0 0 3 0 0 1 0 0 1 0 0 0 0 1 1 0 2 1 0 0 0 1 0 2 1 0 0 2 0 3 0 0 1 1 0 3 0 3 0 0 2 1 0 0 0 1 0 0 1 2 1 1 0 1 0 1 1 1 1 0 2 1 1 0 0 1 0 1 0 1 0 0 0 1 0 2 0 1 2 0 0 0 1 2 1 3 0 1 1 2 1 0 0 1 1 0 2 0 0 1 1 1 1 2 2 0 0 1 2 1 1 2 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 2 0 2 1 2 1 2 3 0 0 3 1 0 1 1 1 0 0 0 0 2 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 2 0 3 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 2 0 1 3 0 0 0 0 0 2 1 0 1 0 0 0 0 0 0 0 2 Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Colab Notebooks/DDP.py\", line 378, in <module>\n","    plt.ylabel('loss')\n","  File \"/content/drive/MyDrive/Colab Notebooks/DDP.py\", line 374, in main\n","    plt.scatter(epochTensor, evalLossTensor, s=20, c='c', label='Eval Loss')\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 281, in spawn\n","    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 237, in start_processes\n","    while not context.join():\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 117, in join\n","    ready = multiprocessing.connection.wait(\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n"]}],"source":["%cd \"/content/drive/MyDrive/Colab Notebooks\"\n","!python DDP.py --my_model \"ResNet18_WCPC_1000\" --lr 1e-2 --w_mode 'Array' --ps_mode 'Array' --w_ch --ps_ch #--warmstart"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LF15o-MWX5Ep"},"outputs":[],"source":["print(torch.cuda.device_count())"]},{"cell_type":"markdown","metadata":{"id":"OZNHA9597elo"},"source":["#### w/ grad accumulation + mixed precision training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdB_jWdx6n5F"},"outputs":[],"source":["''' Gradient accumulation '''\n","\n","arch_tag2 = \"WLPA_finetune\"\n","\n","def retrain_model(model, optimizer, train_loader, test_loader, device, learning_rate=5e-2, epochs=90):\n","    criterion = nn.CrossEntropyLoss()\n","\n","    model.to(device)\n","    scaler = GradScaler()\n","\n","    # optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=3e-3)\n","    # #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.1, last_epoch=-1)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0, last_epoch= -1, verbose=False) # T_max ...\n","\n","\n","    # # Define optimizer and scheduler for stage 1\n","    # optimizer_stage1 = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-3)\n","    # scheduler_stage1 = torch.optim.lr_scheduler.CosineAnnealingLR(\n","    #     optimizer_stage1, T_max=40, eta_min=1e-4, last_epoch=-1, verbose=False)\n","\n","    # # Define optimizer and scheduler for stage 2\n","    # optimizer_stage2 = optim.SGD(model.parameters(), lr=learning_rate/5, momentum=0.9, weight_decay=5e-3)\n","    # scheduler_stage2 = torch.optim.lr_scheduler.CosineAnnealingLR(\n","    #     optimizer_stage2, T_max=60, eta_min=1e-4, last_epoch=-1, verbose=False)\n","\n","\n","    best_eval = -1\n","    best_epoch = 0\n","\n","    model.eval()\n","    eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader,\n","                                            device=device, criterion=criterion)\n","    print(\"Epoch: {:03d} Eval Loss: {:.4f} Eval Acc: {:.4f}\".format(0, eval_loss, eval_accuracy))\n","\n","    trainLossTensor = torch.empty((epochs,), dtype=torch.float64)\n","    evalLossTensor = torch.empty((epochs,), dtype=torch.float64)\n","    epochTensor = torch.empty((epochs,), dtype=torch.int64)\n","    evalAccTensor = torch.empty((epochs,), dtype=torch.float64)\n","\n","    accumulation_steps = 4\n","\n","    %cd \"/content/drive/MyDrive/Colab Notebooks/Psum quant/ImageNet\"\n","    for epoch in range(epochs):\n","    #   if epoch >= 200:\n","    #     optimizer = optimizer_stage2\n","    #     scheduler = scheduler_stage2\n","    #     for i in range(9):\n","    #         model.layers[i].conv0.psumOpt = True\n","    #         model.layers[i].conv1.psumOpt = True\n","    #   else:\n","    #     optimizer = optimizer_stage1\n","    #     scheduler = scheduler_stage1\n","    #     for i in range(9):\n","    #         model.layers[i].conv0.psumOpt = False\n","    #         model.layers[i].conv1.psumOpt = False\n","\n","        # optimizer = optimizer_stage1\n","        # scheduler = scheduler_stage1\n","\n","        # Training\n","        epochTensor[epoch] = epoch\n","        model.train()\n","        running_loss = 0\n","        running_corrects = 0\n","\n","        for i, (inputs, labels) in enumerate(train_loader):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            with autocast():\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels) / accumulation_steps\n","            scaler.scale(loss).backward()\n","\n","            # optimizer.zero_grad()\n","            # outputs = model(inputs)\n","            # _, preds = torch.max(outputs, 1)\n","            # loss = criterion(outputs, labels) / accumulation_steps\n","            # loss.backward()\n","\n","            # # gradient clipping\n","            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n","            if (i + 1) % accumulation_steps == 0:\n","                # optimizer.step()  # Update model weights\n","                # optimizer.zero_grad()  # Reset gradients\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","\n","            running_loss += loss.item() * inputs.size(0) * accumulation_steps\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        # print('TIME ELAPSED GROUP CONV:', time.perf_counter()-start)\n","        train_loss = running_loss / len(train_loader.dataset)\n","        train_accuracy = running_corrects / len(train_loader.dataset)\n","        trainLossTensor[epoch] = train_loss\n","\n","        # Evaluation\n","        model.eval()\n","        eval_loss, eval_accuracy = evaluate_model(model=model,\n","                                                test_loader=test_loader,\n","                                                device=device, criterion=criterion)\n","        evalLossTensor[epoch] = eval_loss\n","        evalAccTensor[epoch] = eval_accuracy\n","\n","        scheduler.step()\n","        print(\"Epoch: {:03d} Train Loss: {:.4f} Train Acc: {:.4f} Eval Loss: {:.4f} Eval Acc: {:.4f}\".format(epoch+1, train_loss, train_accuracy, eval_loss, eval_accuracy))\n","        # ####################################\n","        # if epoch%10==0:\n","        #     cnt=0\n","        #     for i in range(9):\n","        #         ps0 = model.layers[i].conv1.split_conv[0].ps_quan_fn[0]\n","        #         # ps1 = model.layers[i].conv1.split_conv[1].ps_quan_fn[0]\n","\n","        #         int0 = ps0.x_q_int\n","        #         clip0 = ps0.x_q_int_clip\n","        #         # int1 = ps1.x_q_int\n","        #         # clip1 = ps1.x_q_int_clip\n","\n","        #         plt.subplot(3,3,cnt+1)\n","        #         plt.ticklabel_format(style = 'plain')\n","        #         plt.hist(int0.cpu().detach().numpy().flatten(), label='x_int0')\n","        #         plt.hist(clip0.cpu().detach().numpy().flatten(), alpha=0.8, label='x_clip0')\n","        #         # plt.legend()\n","        #         cnt += 1\n","        #     plt.show()\n","        #     # print(model.layers[0].conv1.split_conv[0].ps_quan_fn[0].sf)\n","        # ####################################\n","\n","        # Save best model\n","        if eval_accuracy > best_eval:\n","            best_eval = eval_accuracy\n","            best_epoch = epoch+1\n","\n","            print('Saving..')\n","            state = {\n","                'net': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'acc': best_eval,\n","                'epoch': epoch,\n","            }\n","            if not os.path.isdir('checkpoint'):\n","                os.mkdir('checkpoint')\n","            torch.save(state, './checkpoint/'+arch_tag2+'_ckpt.pt')\n","\n","        if epoch%10 == 0:\n","            plt.figure(figsize=(5,3))\n","            plt.grid(color='k', linestyle='--', linewidth=1)\n","            plt.scatter(epochTensor[:epoch+1], trainLossTensor[:epoch+1], s=20, label='Train Loss')\n","            plt.scatter(epochTensor[:epoch+1], evalLossTensor[:epoch+1], s=20, label='Eval Loss')\n","\n","            plt.title('Train Loss vs. Eval Loss')\n","            plt.xlabel('epochs')\n","            plt.ylabel('loss')\n","            plt.legend(loc='upper right')\n","\n","            plt.show()\n","\n","        # # Save train log\n","        # loss_np = evalLossTensor.cpu().numpy()  #convert to Numpy array\n","        # df = pd.DataFrame(loss_np)              #convert to a dataframe\n","        # df.to_csv(\"./loss log/evalLoss_\"+arch_tag2+\".csv\",index=False)       #save to file\n","\n","        # acc_np = evalAccTensor.cpu().numpy()  #convert to Numpy array\n","        # df = pd.DataFrame(acc_np)              #convert to a dataframe\n","        # df.to_csv(\"./loss log/evalAcc_\"+arch_tag2+\".csv\",index=False)       #save to file\n","\n","    print(\"Best eval accuracy: {:.4f} @ epoch {:03d}\".format(best_eval, best_epoch))\n","\n","    # plot\n","    plt.figure(figsize=(10,6))\n","    plt.grid(color='k', linestyle='--', linewidth=1)\n","    plt.scatter(epochTensor, trainLossTensor, s=20, c='m', label='Train Loss')\n","    plt.scatter(epochTensor, evalLossTensor, s=20, c='c', label='Eval Loss')\n","\n","    plt.title('Train Loss vs. Eval Loss')\n","    plt.xlabel('epochs')\n","    plt.ylabel('loss')\n","    plt.legend(loc='upper right')\n","\n","    plt.show()\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5_tjZ65nMe8"},"outputs":[],"source":["def calibrate_model(model, loader, device=torch.device('cpu')):\n","  model.to(device)\n","  model.eval()\n","\n","  for inputs, labels in loader:\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","    _ = model(inputs)"]},{"cell_type":"markdown","metadata":{"id":"9BH5jMMA_VDJ"},"source":["### random seeds / load cifar-100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jss4sn0bnOxf"},"outputs":[],"source":["def set_random_seeds(random_seed=0):\n","\n","  torch.manual_seed(random_seed)\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False\n","  np.random.seed(random_seed)\n","  random.seed(random_seed)\n","\n","# batch_size=256\n","\n","# transform_train = transforms.Compose([\n","#     transforms.RandomCrop(32, padding=4),  #resises the image so it can be perfect for our model.\n","#     transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n","#     transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n","# #   transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276)) #Normalize all the images\n","#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))\n","# ])\n","\n","# transform = transforms.Compose([\n","#     transforms.ToTensor(),\n","#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","# ])\n","\n","# trainset = torchvision.datasets.CIFAR100(root='./data',\n","#                                         train=True,\n","#                                         download=True,\n","#                                         transform=transform_train)\n","# trainloader = torch.utils.data.DataLoader(trainset,\n","#                                             batch_size=batch_size,\n","#                                             shuffle=True,\n","#                                             num_workers=2)\n","# testset = torchvision.datasets.CIFAR100(root='./data',\n","#                                         train=False,\n","#                                         download=True,\n","#                                         transform=transform)\n","# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","#                                         shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"0r5X-GUZZquR"},"source":["\n","\n","---\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1EQDh6jvGoovBnR-M1RjEaNyIs43XqQPX","timestamp":1722760758855},{"file_id":"1gi2GhXU2RGScbbIDhwpKtGGtu51cYbQy","timestamp":1701171154232}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}